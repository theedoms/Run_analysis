---
title: "CodeBook"
author: "Dominique VERDEJO"
date: "Sunday, May 24, 2015"
output: html_document
---

Project instructions
The purpose of this project is to demonstrate your ability to collect, work with, and clean a data set. The goal is to prepare tidy data that can be used for later analysis. You will be graded by your peers on a series of yes/no questions related to the project. You will be required to submit: 1) a tidy data set as described below, 2) a link to a Github repository with your script for performing the analysis, and 3) a code book that describes the variables, the data, and any transformations or work that you performed to clean up the data called CodeBook.md. You should also include a README.md in the repo with your scripts. This repo explains how all of the scripts work and how they are connected.  

One of the most exciting areas in all of data science right now is wearable computing - see for example this article . Companies like Fitbit, Nike, and Jawbone Up are racing to develop the most advanced algorithms to attract new users. The data linked to from the course website represent data collected from the accelerometers from the Samsung Galaxy S smartphone. A full description is available at the site where the data was obtained: 

http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones 

Here are the data for the project: 

https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip 

You should create one R script called run_analysis.R that does the following. 
 
  Merges the training and the test sets to create one data set.

  Extracts only the measurements on the mean and standard deviation for each measurement. 
  
  Uses descriptive activity names to name the activities in the data set.
  
  Appropriately labels the data set with descriptive variable names. 
  
  From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

Good luck!
```{r}
library(dplyr)
```

Preliminary work
Setup the working directory and git init it
git ignore the Rstudio project files
.Rproj.user
Run_analysis.Rproj

Step 1 : getting the data
download the zip file containing the raw data
```{r, echo = TRUE}
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", "Dataset.zip", method = "curl")
```
Git ignore the file Dataset.zip

Step 2 : 
Open Dataset.zip and extract content to working directory

```{r, echo=TRUE}
unzip("Dataset.zip", files = NULL, list = FALSE, overwrite = TRUE,
      junkpaths = FALSE, exdir = ".", unzip = "internal",
      setTimes = FALSE)
```

Git ignore the initial Dataset directory in .gitignore
UCI HAR Dataset

Step 3 :
View README.txt file in Dataset directory

Step 4 :

Take a look at the files by using read.table with nly a few lines


```{r}

dataDir<-"./UCI HAR Dataset"

tbl_df(read.table(paste(dataDir,"test/X_test.txt", sep="/"), nrows = 10)) ->test_set
tbl_df(read.table(paste(dataDir,"test/y_test.txt", sep="/"), nrows = 10)) ->test_labels
tbl_df(read.table(paste(dataDir,"test/subject_test.txt", sep="/"), nrows = 10)) ->test_subjects


tbl_df(read.table(paste(dataDir,"train/X_train.txt", sep="/"), nrows = 10)) ->training_set
tbl_df(read.table(paste(dataDir,"train/y_train.txt", sep="/"), nrows = 10)) ->training_labels
tbl_df(read.table(paste(dataDir,"train/subject_train.txt", sep="/"), nrows = 10)) ->train_subjects

tbl_df(read.table(paste(dataDir,"features.txt", sep="/"), nrows = 10)) ->features


```

> test_set
Source: local data frame [10 x 561]
> test_labels
Source: local data frame [10 x 1]
> test_subjects
Source: local data frame [10 x 1]
> training_set
Source: local data frame [10 x 561]
> training_labels
Source: local data frame [10 x 1]
> train_subjects
Source: local data frame [10 x 1]
> features
Source: local data frame [10 x 2]


* Merging training and test datasets

Load complete data files

```{r}
tbl_df(read.table(paste(dataDir,"test/X_test.txt", sep="/"))) ->test_set
tbl_df(read.table(paste(dataDir,"test/y_test.txt", sep="/"))) ->test_labels
tbl_df(read.table(paste(dataDir,"test/subject_test.txt", sep="/"))) ->test_subjects


tbl_df(read.table(paste(dataDir,"train/X_train.txt", sep="/"))) ->training_set
tbl_df(read.table(paste(dataDir,"train/y_train.txt", sep="/"))) ->training_labels
tbl_df(read.table(paste(dataDir,"train/subject_train.txt", sep="/"))) ->training_subjects

tbl_df(read.table(paste(dataDir,"features.txt", sep="/"))) ->features
tbl_df(read.table(paste(dataDir,"activity_labels.txt", sep="/"))) ->activity_labels
```


Checking data consistency
> dim(test_set)
[1] 2947  561
> dim(test_labels)
[1] 2947    1
> dim(test_subjects)
[1] 2947    1
> dim(training_set)
[1] 7352  561
> dim(train_subjects)
[1] 7352    1
> dim(training_labels)
[1] 7352    1

Data dimensions indicate that merging should be done by row binding
resulting dataset will have 563 columns and 7352+2947 lines

Binding columns of datasets and corresponding labels

```{r}
test_set<-cbind(test_labels,test_set)
test_set<-cbind(test_subjects,test_set)
training_set<-cbind(training_labels,training_set)
training_set<-cbind(training_subjects,training_set)
```
Binding rows of test and training datasets

```{r}
dataset<-rbind(test_set,training_set) # superposing tables
names(dataset)=c("subject","activity",as.character(features$V2)) # naming variables
dataset$activity<-factor(dataset$activity)
dataset$subject<-factor(dataset$subject)
```
* Extracts only the measurements on the mean and standard deviation for each measurement of related activity

```{r}
dataset<-dataset[,names(dataset)[grep("subject|activity|std|mean",names(dataset))]] #subsetting relevant columns
```
* Uses descriptive activity names to name the activities in the data set.
```{r}
levels(dataset$activity)=activity_labels$V2
```
From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
```{r}
dataset %>%
  group_by (subject,activity) %>%
  summarise_each(funs(mean))->new_dataset

write.table(new_dataset,"new_dataset.txt", row.name = FALSE)
message("\nDone")
```

